{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Irreducibility and Aperiodicity\n",
    "\n",
    "**Definition of period.**  Let $T(x) := {t\\geq1 : P^t(x,x)>0}$ be the set of times when it is possible for the chain to return to starting point $x$. The `period` of a state $x$ is defined as the greatest common divisor (gcd) of the elements of $T(x)$. A state $x$ is called `aperiodic` if its period is 1.\n",
    "\n",
    "**Nice proof for Lemma 1.6**: https://www.math.uchicago.edu/~may/VIGRE/VIGRE2009/REUPapers/Dabbs.pdf \n",
    "\n",
    "Proof goes as follows: \n",
    "\n",
    "\n",
    "Define $g_y = gcd(T(y))$ and $g_x = gcd(T(x))$.  \n",
    "Fix two states $x$ and $y$. There exists some non-negative integers $r$ and $s$ such that\n",
    "\n",
    "$$\n",
    "P^r(x,y) > 0 \\quad \\text{and} \\quad P^s(y,x) > 0\n",
    "$$\n",
    "\n",
    "Then for any $a\\in T(x)$ we have: \n",
    "\n",
    "$$\n",
    "P^{a+r+s}(y,y) \\geq P^s(y,x) \\cdot P^a(x,x) \\cdot P^r(x,y) > 0  \n",
    "$$\n",
    "\n",
    "First inequality is coming from the fact that restricting the path from y to y can not increase the likelihood. \n",
    "\n",
    "Hence for all $a \\in T(x)$, $a+r+s \\in T(y)$ and we know that $r+s \\in T(y)$ from the definitions above. This means $g_y$ divides $r+s$ and $a+r+s$. Thus $g_y$ must also divide all $a\\in T(y)$. This means $g_y$ must be a common divisor of $T(x)$ and divides $g_x$. \n",
    "\n",
    "Since we can make all the same arguments with $x$ and $y$ swapped, this means $g_x=g_y$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "======>>>>> Proposition 1.7 I did not really understand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Periodicity and Lazy Random Walk\n",
    "\n",
    "Suppose we have a chain with period=2. An example would be a chain that is a simple random walk on a cycle of even length: at state $x$ go to $x-1$ with probability $1/2$ and go $x+1$ otherwise. This chain will never mix since it will always stay in one of the two sets of states of opposite parity. If $x_0$ is an even state at time $2t$ it will always be on an even state and at time $2t+1$ it will always be on an odd state.\n",
    "\n",
    "**Lazy Random Walk**\n",
    "\n",
    "There is a simple fix to convert all such chains into aperiodic ones. Given an arbitrary transition matrix $P$ (assume it is periodic), let $Q = \\dfrac{I+P}{2}$ where $I$ is the identity matrix. This is called a lazy random walk since with probability $1/2$ it stays put and with probability $1/2$ it moves according to $P$. Since $Q$ has a self loop of $1/2$ at every state, it is aperiodic. That is for all $x$, $Q(x,x)>0$ which means $gcd(Q)=1$. $Q$ is called a lazy version of $P$. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Stationary Distributions\n",
    "\n",
    "Stationary distribution $\\pi$ is a probability measure satisfying $\\pi = \\pi P$. Clearly if $\\mu_0 = \\pi$ then $\\mu_t=\\pi$ for all $t$.\n",
    "\n",
    "Note that having such stationary distribution is not sufficient to conclude that the chain will converge to it, starting from an arbitrary initial distribution. We need to first prove that the chain gets close to stationary distribution in finite time.\n",
    "\n",
    "\n",
    "Next, we prove something strong about irreducible markov chains. We will show that not only there is a non-zero probability to reach from any state x to y in $t$ steps where t is finite, but also that the expectation of _hitting_ any state $y$ starting from any state $x$ in an irreducible markov chain is finite!! \n",
    "\n",
    "Let's first define hitting and return times.\n",
    "\n",
    "\n",
    "**Definition** Hitting time.\n",
    "\n",
    "$\\tau_x := min\\{t \\geq 0:X_t = x\\}$ is the first passage time or hitting time to state x. When we only consider visits at a positive time, we also define:\n",
    "\n",
    "$$\n",
    "\\tau^+_x := min\\{t \\geq 1:X_t = x\\}\n",
    "$$\n",
    "\n",
    "and when $X_0 = x$,   $\\tau^+_x$ is also called as *first return time*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_LEMMA 1.13. For any states x and y of an irreducible chain, $E_x(\\tau^+_y) < \\infty$ ._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proof** \n",
    "\n",
    "Remember that from the definition of irreducibility, there exists $r$ such that for any $(x,y)$ pair, there exists $j \\leq r$ and $\\epsilon>0$ such that $P^j(x,y) \\geq \\epsilon$. So for any value of of $X_t$, the probability of being in any other state after $r$ steps is at least $e$. Since the behavior of the chain is independent of the path to any $X_t$, we have:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "P_x(\\tau_y^+ > kr) &\\leq (1-\\epsilon) \\cdot P_x(\\tau_y^+ > (k-1)r) \\\\\n",
    "P_x(\\tau_y^+ > kr) &\\leq (1-\\epsilon)^k\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "for $k>0$. Take $k=2$. $P_x(\\tau_y^+ > 2r)$ means that we have to satisfy $P_x(\\tau_y^+ >r)$ and then we have to satisfy $P_x(\\tau_y^+ > 2r)$ given that we didn't hit in $r$ steps. Since the future is independent of the path in the first r steps, these two probabilities are equal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "**Recall.** For any non-negative and integer valued random variable $Y$, we have:\n",
    "\n",
    "$$\n",
    "E(Y) = \\sum_{t \\geq 0 } P(Y>t)\n",
    "$$\n",
    "\n",
    "**Proof.** Rewrite the infinite sum as double sum:\n",
    "\n",
    "$$\n",
    "S =  \\sum_{t \\geq 0 } P(Y>t) = \\sum_{t \\geq 1 } \\sum_{k=t}^{\\infty} P(Y=k) \\\\\n",
    "$$\n",
    "\n",
    "Then, separate each sum:\n",
    "\n",
    "$$\n",
    "S = \\sum_{k=1}^{\\infty} P(Y=k)  + \\sum_{k=2}^{\\infty} P(Y=k) + \\sum_{k=3}^{\\infty} P(Y=k) + ...\n",
    "$$\n",
    "\n",
    "Observe that:\n",
    "\n",
    "$$\n",
    "\\sum_{k=N}^{\\infty} P(Y=k) =  P(Y=N) + \\sum_{k=N+1}^{\\infty} P(Y=k)\n",
    "$$\n",
    "\n",
    "Applying it to our equation gives us:\n",
    "\n",
    "$$\n",
    "S = P(Y=1) + 2 \\cdot P(Y=2) + 3 \\cdot \\sum_{k=3}^{\\infty} P(Y=k) + \\sum_{k=4}^{\\infty} P(Y=k) + ....\n",
    "$$\n",
    "\n",
    "Thus,  $S = \\sum_{k=1}^{\\infty} k \\cdot P(Y=k) = E(Y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, lets bring it all together. Observe that $P_x(\\tau_y^+>t)$ is a decreasing function of $t$. \n",
    "\n",
    "So we can bound all terms using $P_x(\\tau_y^+ > kr) \\leq (1-\\epsilon)^k$:\n",
    "\n",
    "$$\n",
    "E_x(\\tau_y^+) = \\sum_{t \\geq 0} P_x(\\tau_y^+>t) \\leq \\sum_{k \\geq 0} r\\cdot P_x(\\tau_y^+>kr) \\leq r \\cdot \\sum_{k \\geq 0} (1-\\epsilon)^k \\leq \\infty.\n",
    "$$\n",
    "\n",
    "The last inequality comes from infinite geometric sum since $1-\\epsilon$ is between 0 and 1:\n",
    "\n",
    "$$\n",
    "r\\sum_{k \\geq 0} (1-\\epsilon)^k = \\dfrac{r}{1 - (1-\\epsilon)}  = \\dfrac{r}{\\epsilon}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.3. Existence of a stationary distribution.\n",
    "\n",
    "Above, we proved that the expectation of reaching any state is finite when the Markov chain is irreducible.  \n",
    "\n",
    "Here we will utilize the above lemma to demonstrate a way to construct a stationary distribution for any irreducible chain using the hitting times. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to construct the stationary distribution, we will examine the behavior of the chain between each visit to an arbitrary state $z \\in \\mathcal{X}$. \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\hat{\\pi}(y) &= E_z \\{\\text{Number of visits to y before returning to z} \\} \\\\\n",
    "&= \\sum_{t=0}^{\\infty} P_z(X_t = y, \\tau_z^{+} > t).\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Proposition 1.14_ Let $\\hat{\\pi}$ be a measure on X defined as equation (2) above. Then we will show that \n",
    "\n",
    "1. If $P_z(\\tau_z^+<\\infty)$, then $\\hat{\\pi} = \\hat{\\pi}P$  and \n",
    "2. If $E_z(\\tau_z^+) < \\infty$, then $\\pi := \\dfrac{\\hat{\\pi}}{E_z(\\tau_z^+)}$ is a stationary distribution!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that we already proved $E_z(\\tau_z^+)<\\infty$ to be true for all irreducible chains. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proof for 1.14.** \n",
    "\n",
    "We will check that $\\hat{\\pi}$ is stationary using its definition:\n",
    "\n",
    "$$\n",
    "\\sum_{x \\in \\mathcal{X}} \\hat{\\pi}(x) P(x,y) = \\sum_{x \\in \\mathcal{X}} \\sum_{t=0}^{\\infty} P_z(X_t=x,\\tau_z^+>t) P(x,y) .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the event $\\{\\tau_z^+ \\geq t+1\\} = \\{\\tau_z^+ > t\\}$ is determined by all $X_0, X_1, ...., X_t$. And we have the below identity:\n",
    "\n",
    "$$\n",
    "P_z(X_t=x , X_{t+1}=y, \\tau_z^{+} \\geq t+1) = P_z(X_t=x, \\tau_z^{+} \\geq t+1) P(x,y)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also observe that the order of summation above can be reversed (row-first sum vs col-first sum).   \n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{x \\in \\mathcal{X}} \\hat{\\pi}(x) P(x,y) &=  \\sum_{t=0}^{\\infty}  \\sum_{x \\in \\mathcal{X}} P_z(X_t=x,\\tau_z^+\\geq t+1) P(x,y)\\\\\n",
    "&= \\sum_{t=0}^{\\infty} \\sum_{x \\in \\mathcal{X}}  P_z(X_t=x , X_{t+1}=y, \\tau_z^{+} \\geq t+1) \\\\\n",
    "\n",
    "&=  \\sum_{t=0}^{\\infty} P_z(X_{t+1}=y, \\tau_z^{+} \\geq t+1) \\\\ \n",
    "&= \\sum_{t=1}^{\\infty} P_z(X_{t}=y, \\tau_z^{+} \\geq t)\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Equation (4) above is very similar to the definition of $\\hat{\\pi}$ so we are almost there.   \n",
    "In fact we can rewrite (4) as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{t=1}^{\\infty} P_z(X_{t}=y, \\tau_z^{+} \\geq t) &= \\hat{\\pi}(y) - P_z(X_0 = y, \\tau_z^{+} > 0) + \\sum_{t=1}^{\\infty} P_z(X_t = y, \\tau_z^+ = t )\\\\\n",
    "&= \\hat{\\pi}(y) - P_z(X_0) + P_z(X_{\\tau_z^+} = y) \\\\\n",
    "&=\\hat{\\pi}(y)\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Note that identity $\\sum_{t=1}^{\\infty} P_z(X_t = y, \\tau_z^+ = t) = P_z(X_{\\tau_z^+} = y)$ is correct, as we are summing over all possible values of $t$. So the union of all events can be interpreted as the probability of the chain being at $y$ at time $\\tau_z^+$.   \n",
    "Because that is the only way to satisfy the event $\\{X_t = y, \\tau_z^+ = t\\}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The equality from (2) to (3) follows by considering the two cases:\n",
    "\n",
    "1. If $y=z$, then the last two terms are both 1 and they cancel out.\n",
    "2. If $y\\neq z$, then both terms are 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Therefore, we just showed that:\n",
    "\n",
    "$$\n",
    "\\hat{\\pi}P(y) = \\hat{\\pi}(y)  \\quad \\forall y.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we can get a _probability_ measure simply by normalizing with the sum $\\sum_{x\\in \\mathcal{X}} \\hat{\\pi{}}(x) = E_z(\\tau_z^+)$:  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\pi(x) = \\dfrac{\\hat{\\pi}(x)}{E_z(\\tau_z^+)}. \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**(End of proof for proposition 1.14)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5.4 Uniqueness of the stationary distribution.\n",
    "\n",
    "Above we proved the **existence** of a stationary distribution for an irreducible chain. Next, we will prove its uniqueness.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Harmonic functions** \n",
    "\n",
    "We call distributions that are invariant under right multiplication by P **stationary**. And if a column vector is invariant under a left multiplication, we will call them **harmonic**. \n",
    "\n",
    "That is, a function $h: \\mathcal{X}\\rightarrow \\mathbb{R}$ is harmonic at $x$ if \n",
    "\n",
    "$$\n",
    "h(x) = \\sum_{y\\in \\mathcal{X}} P(x,y) h(y) . \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LEMMA 1.16** Suppose P is irreducible. If $h$ is harmonic at every state of $\\mathcal{X}$, then h must be constant!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Proof**.\n",
    "\n",
    "Assume h is not constant. $\\mathcal{X}$ is finite so there must be a state $x_0$ such that $h(x_0)=M$ is maximal. Since P is irreducible, there must be a state $z$ such that $P(x_0,z)>0$ and $h(z)<M$. If that is the case, we can write:\n",
    "\n",
    "$$\n",
    "h(x_0) = P(x_0,z) h(z) + \\sum_{y\\neq z} P(x_0,y)h(y) < M\n",
    "$$\n",
    "\n",
    "from the definition of $M$ and the fact that the row $P(x_0, .)$ should sum to 1. Therefore we have a contradiction and in fact $h(z)=M$ for all states $z$ such that $P(x_0,z)>0$.\n",
    "\n",
    "Finally, for any $y \\in \\mathcal{X}$, irreducibility tells us that there is a sequence $x_0,x_1,...,x_n=y$ such that $P(x_i,x_{i+1})>0$. Above argument then shows that $h(y) = h(x_{n-1}) = ... = h(x_0) = M$. Thus, $h$ is constant.\n",
    "\n",
    "Next we will use this lemma to prove the uniqueness of the stationary distribution. But in order to do that we need revisit some basic linear algebra!  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear Algebra recap\n",
    "\n",
    "(Feel free to skip this if you are fresh with these concepts).\n",
    "\n",
    "\n",
    "**Kernel of a matrix.**\n",
    "\n",
    "\n",
    "Kernel of a matrix ($A$) is the collection of all vectors $x$ such that $Ax=0$. The space spanned by this kernel is referred to as the null space of A. \n",
    "\n",
    "Dimension of the kernel is the number of independent vectors included in the kernel. In the above lemma 1.16, when P is irreducible, $(P-I)h=0$ has only one solution of form:\n",
    "\n",
    "$$\n",
    "Y = s \\begin{bmatrix}\n",
    "1\\\\\n",
    "1\\\\\n",
    "1\\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "where $s$ is arbitrary but can only have one value if $h$ is a probability distribution (sum to 1). \n",
    "\n",
    "\n",
    "**Elementary Operations**\n",
    "\n",
    "Let's define elementary row and column operations in a matrix and later show why they do not alter the column or row rank of a matrix.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Elementary Matrix.**  \n",
    "\n",
    "See definition here: https://en.wikipedia.org/wiki/Elementary_matrix#Elementary_row_operations\n",
    "\n",
    "In short elementary matrices are obtained from $I$ by a single row operation:\n",
    "\n",
    "- row switching: switch row1 and row2\n",
    "- row multiplication: multiply rown by non-zero constant.\n",
    "- row addition: add a multiple of rowi to rowj\n",
    "\n",
    "Same three operations can be said for column as well. So there are six types of operations in total.\n",
    "\n",
    "\n",
    "**Theorem.** Matrix multiplication is associative.\n",
    "\n",
    "$$\n",
    "A(BC) = (AB)C\n",
    "$$\n",
    "\n",
    "Proof: https://math.stackexchange.com/questions/2912743/proving-associativity-of-matrix-multiplication \n",
    "\n",
    "Proof idea: Simply expand left hand side and right hand side, you will end up with identical double sum over multiplication of scalars. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Theorem.** Multiplication by an invertible matrix preserves rank.\n",
    "\n",
    "_Proof._\n",
    "\n",
    "Imagine $(m,n)$ matrix $A$. Its column rank is defined by number $n-c$ where c is the dimension of its null space, i.e., dimension of the subspace spanned by all vectors $q$ that satisfy: $Aq=0$. \n",
    "\n",
    "For an invertible matrix $U$, consider $UAq=0$. Due to associativity, clear we have:\n",
    "\n",
    "$$\n",
    "rank(A) \\leq rank(UA)\n",
    "$$\n",
    "\n",
    "Now consider the inverse of $U$, $U^{-1}$. Multiply $UA$ by this matrix to get $A$. Then, by repeating the same argument we have:\n",
    "\n",
    "$$\n",
    "rank(UA) \\leq rank(A)\n",
    "$$.\n",
    "\n",
    "So $rank(UA)$ and $rank(A)$ must be equal.\n",
    "\n",
    "Question: How about right multiplication though? \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Theorem.**  \"row rank equals column rank\". \n",
    "\n",
    "\n",
    "_Proof._\n",
    "\n",
    "Reference: https://math.stackexchange.com/a/81903 \n",
    "\n",
    "In order to prove this theorem, we will prove that the column rank of a matrix $A$ is equal to the column rank of its transpose $A^t$. \n",
    "\n",
    "Let's define col rank(A) as $dim\\{Ax:x\\in \\mathbb{R}^n\\}$. First let's show that $A^tAx=0$ **if and only if** $Ax=0$. First direction is trivial from associativity of matrix multiplication: If $Ax=0$, then $A^tAx=0$. \n",
    "\n",
    "For the other direction:\n",
    "\n",
    "$$\n",
    "A^tAx=0 \\implies x^t A^t A x = 0 \\implies (Ax)^t Ax = 0 \\implies Ax = 0 \n",
    "$$\n",
    "\n",
    "\n",
    "So we have shown that $rank(A)=rank(A^tA)\\leq rank(A^t)$. The last inequality is coming from the fact that rows of $A^tA$ are linear combinations of the columns of $A^t$ so its column rank can not be greater. \n",
    "\n",
    "\n",
    "To finish the proof, simply repeat the same argument starting with $A^t$ and its transpose $A$. \n",
    "\n",
    "\n",
    "See also proof from [MIT linear algebra course](https://ocw.mit.edu/courses/18-701-algebra-i-fall-2010/dfd72d3d4a11988c2335b5e9a79ce48b_MIT18_701F10_rrk_crk.pdf ) uses elementary row/column operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Corollary 1.17._    \n",
    "    (Corollary of Lemma 1.16)\n",
    "\n",
    "Let $P$ be the transition matrix of an irreducible markov chain. There exists a _unique_ probability distribution $\\pi$ such that $\\pi = \\pi P$.\n",
    "\n",
    "_Proof._\n",
    "\n",
    "In lemma 1.16 we proved if $Px=x \\implies x$ is constant. This means the solution for $(P-I)x=0$ is only the set of all vectors which are of the form:\n",
    "\n",
    "$$\n",
    "x = s \\begin{bmatrix}\n",
    "1\\\\\n",
    "1\\\\\n",
    "1\\\\\n",
    "1\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "In other words, the nullspace of $(P-I)$ has the dimension 1. Since \"row rank equals column rank\" and P is a square matrix, row rank should also be of size $\\mathcal{X}-1$. \n",
    "\n",
    "$$\n",
    "\\mathcal{v} = \\mathcal{v} P\\\\\n",
    "0 = \\mathcal{v}(P-I)\n",
    "$$\n",
    "\n",
    "should have a 1 dimensional space of solutions. There exists only one vector in this space whose entries sum up to 1. QED"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Proposition 1.19_ \n",
    "\n",
    "If $P$ is the transition of an irreducible markov chain, and its unique stationary distribution is $\\pi$, then $\\forall z$:\n",
    "\n",
    "$$\n",
    "\\pi(z) = \\dfrac{1}{E_z(\\tau_z^+)} . \n",
    "$$\n",
    "\n",
    "\n",
    "_Proof._\n",
    "\n",
    "\n",
    "In proposition 1.14, we proved $\\hat{\\pi}_z(y)$ was the stationary distribution. Since it is unique, $\\pi(y) = \\dfrac{\\hat{\\pi}(y)}{{E_z(\\tau_z^+)}}$. Then, \n",
    "\n",
    "$$\n",
    "\\pi_z(z) = \\pi(z) = \\dfrac{\\hat{\\pi}(z)}{{E_z(\\tau_z^+)}} = \\dfrac{1}{{E_z(\\tau_z^+)}} \\quad \\blacksquare\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above proposition is very very intuitive if you think about it. Imagine a chain that is simulated for a very long time. The amount of time it takes for each state to return should give how often we visit each state, which is the same thing as the long term stationary distribution one would expect.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Reversibility and Time Reversals\n",
    "\n",
    "_Definition._\n",
    "\n",
    "If a probability distribution $\\pi$ on $\\mathcal{X}$ satisfies:\n",
    "\n",
    "$$\n",
    "\\pi(x)P(x,y) = \\pi(y) P(y,x)  \\quad \\forall x,y \\in \\mathcal{X}\n",
    "$$\n",
    "\n",
    "The above equations are called the **detailed balance equations**.\n",
    "\n",
    "\n",
    "_Proposition 1.20._  For a transition matrix $P$ of a markov chain with state space $\\mathcal{X}$, any distribution $\\pi$ that satisfies the detailed balance equiations is **stationary** for P. \n",
    "\n",
    "_Proof._\n",
    "\n",
    "Simply plug the equation in after expanding $\\pi P(x)$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\pi P(x) &= \\sum_{y\\in\\mathcal{X}} \\pi(y) P(y,x)\\\\\n",
    "         &= \\sum_{y\\in\\mathcal{X}} \\pi(x) P(x,y)\\\\\n",
    "         &= \\pi(x) \\sum_{y\\in\\mathcal{X}} P(x,y) = \\pi(x) \\cdot 1 \\quad \\blacksquare\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "One interesting property of when the detailed balance equations is satisfied is the following observation about the sequence probabilities when the initial state is sampled from the stationary distribution:\n",
    "\n",
    "$$\n",
    "\\pi(x_0) P(x_0,x_1) P(x_1,x_2) ... P(x_{n-1},x_n) = \\pi(x_n) P(x_n,x_{n-1}) P(x_2,x_1) ... P(x_{1},x_0) . \n",
    "$$\n",
    "\n",
    "Why? Repeat the below replacement operation for sequence of length $n$:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\pi(x_0) P(x_0,x_1) P(x_1,x_2)  P(x_2,x_3) &=  \\pi(x_1) P(x_1,x_0)  P(x_1,x_2)  P(x_2,x_3) \\\\\n",
    "                                           &=  \\pi(x_2)  P(x_2,x_1) P(x_1,x_0)  P(x_2,x_3) \\\\\n",
    "                                           &= \\pi(x_3) P(x_3,x_2) P(x_2,x_1) P(x_1,x_0) .\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "\n",
    "The above equation shows that the sequence starting from stationary distribution has same probability with going that sequence backwards in time. For this reason, a chain that satisfies the detailed balance equation is called **reversible**. To put that in notation:\n",
    "\n",
    "$$\n",
    "P_{\\pi}(X_0,X_1,..., X_{n-1},X_n) = P_{\\pi}(X_n,X_{n-1},..., X_{1},X_0) . \n",
    "$$\n",
    "\n",
    "\n",
    "=============== [TODO] Add some examples here on reversible chains in simulation code. ==============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Definition._ For an irreducible markov chain with transition matrix $P$ and stationary distribution $\\pi$, below matrix is called its **time reversal**: \n",
    "\n",
    "$$\n",
    "\\hat{P}(x,y) = \\dfrac{\\pi(y)P(y,x)}{\\pi(x)}.\n",
    "$$\n",
    "\n",
    "Observe that $\\hat{P}$ is _stochastic_ since $\\pi$ is the stationary distribution. \n",
    "\n",
    "Pick any row $\\hat{P}(y,.)$ and check its sum:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\sum_{x \\in \\mathcal{X}} \\hat{P}(y,x) &= \\sum_{x \\in \\mathcal{X}} \\dfrac{\\pi(y)P(y,x)}{\\pi(x)} \\\\\n",
    "&= \\sum_{x \\in \\mathcal{X}} \\dfrac{\\pi(x)P(x,y)}{\\pi(y)} \\\\\n",
    "&= \\dfrac{1}{\\pi(y)}\\sum_{x \\in \\mathcal{X}} \\pi(x)P(x,y)\\\\\n",
    "&= \\dfrac{1}{\\pi(y)} \\cdot \\pi(y) = 1\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Last line is achieved since $\\pi$ is stationary.\n",
    "\n",
    "Next we prove two nice properties about time reversal of a transition matrix.\n",
    "\n",
    "\n",
    "_Proposition 1.23._  Let $X_t$ be an irreducible markov chain with $P$ and $\\pi$. Denote $\\hat{X}_t$ as the time-reversed chain with transition matrix $\\hat{P}$ as defined above.\n",
    "\n",
    "Then $\\pi$ is stationary for $\\hat{P}$ and for any sequence we have:\n",
    "\n",
    "\n",
    "$$\n",
    "P_{\\pi }(X_0=x_0, X_1=x_1, ... , X_t=x_t) = \\hat{P}_{\\pi}(\\hat{X}_0 = x_t,\\hat{X}_0 = x_{t-1},\\hat{X}_0 = x_t,).\n",
    "$$\n",
    "\n",
    "_Proof._\n",
    "\n",
    "To prove that $\\pi$ is stationary, we check that:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\pi \\hat{P}(x) = \\sum_{y \\in \\mathcal{X}} \\pi(y) \\hat{P}(y,x) &= \\sum_{y \\in \\mathcal{X}} \\pi(y) \\dfrac{\\pi(x)P(x,y)}{\\pi(y)}\\\\\n",
    "                                                              &= \\pi(x) \\sum_{y \\in \\mathcal{X}} \\pi(y)\\dfrac{P(x,y)}{\\pi(y)}\\\\\n",
    "                                                              &= \\pi(x) \\cdot 1 .\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "To check that the trajectories have the same probability, simply plugin the definition of $\\hat{P}$.\n",
    "\n",
    "**Important Notice** If $P$ is reversible $\\hat{P}=P$ from the definition of time reversal. And also remember that time reversal can be computed for any irreducible markov chain (doesn't necessarily have to be reversible).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Classifying the States of a Markov Chain\n",
    "  \n",
    "Summary: When a chain is irreducible, all states are accessible by all states. Not much to analyze in terms of types of states/nodes. However, when irreducibility is not satisfied, we can think of the chain as consisting of multiple groups.\n",
    "\n",
    "This section is for classifying the states when irreducibility is not met.\n",
    "\n",
    "### Some Definitions and Notation\n",
    "\n",
    "y **is accessible from** x if $\\exists r>0,\\quad P^r(x,y)>0$. Notation: $x \\rightarrow y$.\n",
    "\n",
    "\n",
    "**essential** state: If for all y such that $x \\rightarrow y$, it is also true that $y\\rightarrow x$, we call $x$ essential.\n",
    "\n",
    "**inessential** state: When x is not essential.\n",
    "\n",
    "x **communicates with** y $x\\leftrightarrow y$: If and only if $x\\rightarrow y$ and $y \\rightarrow x$, or $x=y$! The equivalence classes under $\\leftrightarrow$ is called **communicating classes**. We done the communicating class of a state $x$ by $[x]$. \n",
    "\n",
    "**absorbing** state is a state such that once chain arrives $x$ it never leaves it. If a communicating class $[x]=\\{x\\}$ (that is only 1 element) is essential, it is absorbing.\n",
    "\n",
    "On the other hand, if a communicating class is inessential, once the chain leaves the communicating class, it never comes back. Draw few examples to check it.\n",
    "\n",
    "\n",
    "_Lemma 1.25._ If x is essential and $x\\rightarrow y$, then y is also  essential. \n",
    "\n",
    "_Proof._\n",
    "\n",
    "If $y \\rightarrow z$, then $x\\rightarrow z$. Since x is essential this implies, $z \\rightarrow x$. Thus, there is a path from z to y at least through x and $z \\rightarrow y. \\blacksquare$ \n",
    "\n",
    "\n",
    "Important consequence of the above lemma is that, the states in a single communicating class are **either all** essential or **all** inessential!! To better intuit about this, I think I highly recommend drawing several examples. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Proposition 1.28._ For a finite markov chain with $P$, if $\\pi$ is a stationary distribution for $P$ then $\\pi(y_0)=0$ for all inessential states $y_0$. \n",
    "\n",
    "_Proof._ \n",
    "\n",
    "Let $\\mathcal{C}$ be an essential communicatin class. Then we have the following:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\pi P(C) = \\sum_{z \\in C} \\pi P(z) &= \\sum_{z \\in C} \\left[ \\sum_{y \\in C} \\pi(y) P(y,z) + \\sum_{y \\notin C} \\pi(y) P(y,z)  \\right]\\\\ \n",
    "\\text{(reverse order of summation)}&= \\sum_{y \\in C}  \\sum_{z \\in C} \\pi(y) P(y,z) + \\sum_{z \\in C} \\sum_{y \\notin C} \\pi(y) P(y,z) \\\\\n",
    "&= \\sum_{y \\in C} \\pi(y)\\cdot 1 + \\sum_{z \\in C} \\sum_{y \\notin C} \\pi(y) P(y,z)\\\\\n",
    "&= \\pi(C) +  \\sum_{z \\in C} \\sum_{y \\notin C} \\pi(y) P(y,z) \\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "Last equation tells us that $\\forall y \\notin C$ and  $z \\in C$ $\\pi(y) P(y,z)=0$. \n",
    "\n",
    "Finally we use simple observation to finish the proof (using Lemma 1.26 in the book).\n",
    "\n",
    "Lemma 1.26 demonstrates that there exists a sequence of inessential states such that $y_0,...,y_{r-1}$ each satisfying $P(y_{i-1}, y_{i})>0$ and $P(y_{r-1},y_r)>0$ with $y_r$ being an essential state. \n",
    "\n",
    "Since we proved that $\\pi(y_{r-1})P(y_{r-1},y_r)=0$ and  $P(y_{r-1},y_r)>0$ this means $\\pi(y_{r-1})=0$\n",
    "\n",
    "Next for the remaining sequence of states we go backwards to show that all inessential states $y_i$ above have $\\pi(y_i)=0$ since $\\pi(y_{i+1})=0$ and $P(y_{i},y_{i+1})>0$ (to satisfy $\\pi=\\pi P$). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Proposition 1.29._ The transition matrix P has a unique stationary distribution if and only if there is a unique essential communicating class.\n",
    "\n",
    "_Proof._ Leaving as an exercise, you need to prove for both cases (i.e., true when unique essential class, and also prove false when more than one essential class). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises \n",
    "\n",
    "Here we go over some selected exercises answered in the textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1.** \n",
    "\n",
    "Reference: https://markov-chains.com/week-2-lecture-2/ \n",
    "\n",
    "Given $n$ light bulbs and we know that at starting time only one single light bulb was turned on, what is the expected value of the number of steps until we hit the state with all light bulbs are turned off. At each step, we randomly select one light bulb and flip it.\n",
    "\n",
    "$$\n",
    "\\text{start: } 010\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{end: } 000\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E_1 = \\dfrac{1}{3} \\cdot 1 + \\dfrac{2}{3} \\cdot (1 + E_2)\\\\\n",
    "...\\\\\n",
    "E_2 = \\dfrac{2}{3} \\cdot (1+ E_1) + \\dfrac{1}{3} \\cdot (2 + E_2)\\\\\n",
    "...\\\\\n",
    "...\\\\\n",
    "E_1 = 7 \n",
    "$$\n",
    "\n",
    "$E_j$ expected time to reach 0 given we start from j.\n",
    "\n",
    "$\\tau_j$ expected time to reach j-1 given we start from j.\n",
    "\n",
    "$E_j = \\sum_{n=1}^j \\tau_n$\n",
    "\n",
    "$E_1 = \\tau_1 = 2^n - 1$ where $n$ is the number of light bulbs.\n",
    "\n",
    "$E_5= ? $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets simulate it\n",
    "import numpy as np \n",
    "ns = np.arange(3,11)\n",
    "\n",
    "def simulate(n,s=1):\n",
    "    t = 0\n",
    "    x = s\n",
    "    while x:\n",
    "        r = np.random.random()\n",
    "        if r<(x/n):\n",
    "            x-=1\n",
    "        else:\n",
    "            x = min(n,x+1)\n",
    "        t+=1\n",
    "    return t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 : 3.99436 3\n",
      "3 : 8.9896 7\n",
      "4 : 18.7105 15\n",
      "5 : 37.68202 31\n",
      "6 : 74.67464 63\n"
     ]
    }
   ],
   "source": [
    "for n in [2,3,4,5,6]:\n",
    "    repeat = 100000\n",
    "    runs = [simulate(n,max(2,n)) for _ in range(repeat)]\n",
    "    print(n ,\":\",sum(runs)/len(runs), 2**n -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
